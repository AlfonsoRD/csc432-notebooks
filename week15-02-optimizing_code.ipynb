{
 "metadata": {
  "name": "week15-02-optimizing_code"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Speeding up your code"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    \"Premature optimization is the root of all evil\".\n",
      "                                -Donald Knuth\n",
      "        \n",
      "* Write code how you want it to look then optimize\n",
      "* *But* be smart"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Profile your code"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* This is important\n",
      "* Know where your bottlenecks are\n",
      "* Python has a great built-in profiler [cProfile](http://docs.python.org/2/library/profile.html)\n",
      "* There is also [line_profiler](https://pypi.python.org/pypi/line_profiler) by Robert Kern\n",
      "* [kcachegrind](http://kcachegrind.sourceforge.net/html/Home.html) is another option that includes visualization\n",
      "* Use these!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "An Example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Michael N. has let us use his code as an example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from blackjackr2 import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cProfile\n",
      "import pstats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* First run the code through the profiler"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fout = \"speed_stats.prof\"\n",
      "\n",
      "cProfile.run('runlayer1()', fout)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = pstats.Stats(fout)\n",
      "\n",
      "p.strip_dirs().sort_stats('time').print_stats(10)\n",
      "#p.sort_stats('time').print_stats(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Notice first the number of function calls and the overall time\n",
      "* This is fine for a first pass at timing, the accuracy won't be more than .001 seconds\n",
      "* **ncalls**\n",
      "  * for the number of calls,\n",
      "* **tottime**\n",
      "  * for the total time spent in the given function (and excluding time made in calls to sub-functions)\n",
      "* **percall**\n",
      "  * is the quotient of tottime divided by ncalls\n",
      "* **cumtime**\n",
      "  * is the cumulative time spent in this and all subfunctions (from invocation till exit). This figure is accurate even for recursive functions.\n",
      "* **percall**\n",
      "  * is the quotient of cumtime divided by primitive calls\n",
      "* **filename:lineno(function)**\n",
      "  * provides the respective data of each function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Now what if we *refactor* that part of the code?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* What kind of speed-up did we get?\n",
      "\n",
      "$$S=\\frac{T_{old}}{T_{new}}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1.83/.86"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* If you need memory profiling, consider using [memory_profiler](https://pypi.python.org/pypi/memory_profiler) by one of the scikit-learn developers\n",
      "* This is not in the notebooks repository, but consider the following\n",
      "* Michael E. has agreed to let us use some code from his project"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can install `memory_profiler` with [pip](https://pypi.python.org/pypi/pip):\n",
      "\n",
      "    pip install psutil\n",
      "    pip install memory_profiler"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* `Decorate` the functions that you want to profile with a Python [decorator](http://docs.python.org/2/glossary.html#term-decorator) called `@profile`\n",
      "* You don't have to worry about where this `profile` comes from, it's injected into your script when you run the code as described below\n",
      "* Say we had a script called `run_foreign.py`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    import foreign\n",
      "\n",
      "    @profile\n",
      "    def mem_profile_cython_in_memory():\n",
      "        ustc_stata_reader = foreign.StataReader(open(fname, 'rb'))\n",
      "        test3 = ustc_stata_reader.datasetOO()\n",
      "\n",
      "    @profile\n",
      "    def mem_profile_generator():\n",
      "        test5 = foreign.genfromdta(fname)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We run this file from the command prompt with\n",
      "\n",
      "    python -m memory_profiler run_foreign.py"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Here's an example that is in the notebook repository"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat test_profiler.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run -m memory_profiler test_profiler.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Alternatively, you could import the decorator and use it in your code"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    from memory_profiler import profile\n",
      "    \n",
      "    @profile\n",
      "    def function_to_profile(...)\n",
      "        ..."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Aside: Python Decorators"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* See `python_decorators` notebook"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "IPython.parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* If you'd like go ahead and clone the IPython.parallel talk\n",
      "\n",
      "    git clone git://github.com/jseabold/zorro.git\n",
      "<br /><br />\n",
      "* You'll need to pass the folder you cloned this into to start a new notebook\n",
      "\n",
      "    ipython notebook --notebook-dir=/path/to/zorro\n",
      "<br /><br />\n",
      "* It's specific to AU's HPC cluster (which you don't have access to I think)\n",
      "* **But** the principals work the same on an Amazon EC2 instance\n",
      "* In fact, setup there is perhaps even easier by using [starcluster](http://star.mit.edu/cluster/docs/latest/plugins/ipython.html)\n",
      "* Last I checked academic users got a free 1000 compute hours in their first year\n",
      "* After that it costs fractions of a penny per processor hour"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}