{
 "metadata": {
  "name": "linear_algebra_regression_intro"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Linear Algebra Review"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Transposing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recall that $\\prime$ indicates taking the transpose of a matrix. This just means to swap the rows and the columns of a matrix. So that if \n",
      "\n",
      "$$A = \\left[\\begin{array}{ccc}\n",
      "1 & 2 & 3 \\cr\n",
      "      4 & 5 & 6 \\cr\n",
      "      7 & 8 & 9\\end{array}\\right]$$\n",
      "\n",
      "then\n",
      "\n",
      "$$A^{\\prime} = \\left[\\begin{array}{ccc}\n",
      "      1 & 4 & 7 \\cr\n",
      "      2 & 5 & 8 \\cr\n",
      "      3 & 6 & 9\\end{array}\\right]$$\n",
      "\n",
      "**Properties**\n",
      "\n",
      "$$(A^{\\prime})^{\\prime}=A$$\n",
      "$$(A+B)^{\\prime}=A^{\\prime}+B^{\\prime}$$\n",
      "$$(AB)^{\\prime}=B^{\\prime}A^{\\prime}$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Triangular Matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* A triangular matrix is a square matrix in which all of the elements above or below the diagonal are zero\n",
      "* **Lower** triangular matrix\n",
      "$$L=\\left[\\begin{array}{c c c c c}\n",
      "x_{1,1} & & & & 0 \\cr\n",
      "x_{2,1} & x_{2,2} & & &  \\cr\n",
      "x_{3,1} & x_{3,2} & \\ddots & &  \\cr\n",
      "\\vdots & \\vdots & \\ddots & \\ddots & \\cr\n",
      "x_{n,1} & x_{n,2} & \\cdots & x_{n,n-1} & x_{n,n} \\cr\n",
      "\\end{array}\\right]$$\n",
      "* **Upper** triangular matrix\n",
      "$$U=\\left[\\begin{array}{c c c c c}\n",
      "x_{1,1} & x_{1,2} & \\cdots & x_{1, n-1} & x_{1, n} \\cr\n",
      "& x_{2,2} & x_{2,3} & \\cdots & x_{2,n}  \\cr\n",
      "& & \\ddots & \\ddots & \\vdots \\cr\n",
      "& & & \\ddots & x_{n-1,n} \\cr\n",
      "0 &  & & & x_{n,n} \\cr\n",
      "\\end{array}\\right]$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Multiplication"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Matrix multiplication takes the rows of the matrix that by which you are pre-multiplying and takes linear combination of each row with each column of the matrix by which you are post-multiplying. \n",
      "* To be **conformable** the columns of the $1^{\\text{st}}$ matrix must be equal to the rows of the $2^{\\text{nd}}$ matrix. \n",
      "* The dot product $AB$, $A$ must have the same number of columns as $B$ has rows. \n",
      "* $AB$ has the same number of rows as $A$ and the same number of columns as $B$.  \n",
      "* If A were ($3\\times2$) and B were ($2\\times2$), the result $AB$ would be ($3\\times 2$)\n",
      "* For example,\n",
      "\n",
      "$$A = \\left[\\begin{array}{c c}\n",
      "        2 & 3.5 \\cr\n",
      "        -0.5 & 2.1 \\cr\n",
      "        9 & 0 \\cr\n",
      "\\end{array}\\right]$$\n",
      "\n",
      "and let \n",
      "\n",
      "$$B = \\left[\\begin{array}{c c}\n",
      "            1 & 1.5 \\cr\n",
      "            -4.5 & 5 \\cr\n",
      "\\end{array}\\right]$$\n",
      "\n",
      "Then \n",
      "\n",
      "$$AB=\\left[\\begin{array}{c c}\n",
      "    -13.75 & 20.5 \\cr\n",
      "    -9.95 & 9.75 \\cr\n",
      "        9 & 13.5 \\cr\n",
      "\\end{array}\\right]$$\n",
      "\n",
      "Explicitly, this is\n",
      "\n",
      "$$\\begin{aligned}\n",
      "\\color{blue}{\\text{Row 1, Column 1}} \\cr\n",
      "2\\color{red}{\\times}1 + 3.5\\color{red}{\\times} -4.5 &= -13.75 \\cr\n",
      "\\color{blue}{\\text{Row 1, Column 2}} \\cr\n",
      "2\\color{red}{\\times}1.5 + 3.5\\color{red}{\\times} 5 &= 20.5 \\cr\n",
      "\\color{blue}{\\text{Row 2, Column 1}} \\cr\n",
      "-0.5\\color{red}{\\times}1 + 2.1\\color{red}{\\times} -4.5 &= -9.95 \\cr\n",
      "\\color{blue}{\\text{Row 2, Column 2}} \\cr\n",
      "-0.5 \\color{red}{\\times} 1.5 + 2.1\\color{red}{\\times} 5 &= 9.75 \\cr\n",
      "\\color{blue}{\\text{Row 3, Column 1}} \\cr\n",
      "9 \\color{red}{\\times} 1 + 0 \\color{red}{\\times} -4.5 &= 9 \\cr\n",
      "\\color{blue}{\\text{Row 3, Column 2}} \\cr\n",
      "9 \\color{red}{\\times} 1.5 + 0 \\color{red}{\\times} 5 &= 13.5\n",
      "\\end{aligned}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's check with NumPy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[2, 3.5],\n",
      "              [-.5, 2.1],\n",
      "              [9, 0]])\n",
      "\n",
      "B = np.array([[1, 1.5],\n",
      "              [-4.5, 5]])\n",
      "print A\n",
      "print\n",
      "print B\n",
      "print\n",
      "print np.dot(A, B)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Systems of Equations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose you know that a total of `$`175,000 is invested in three assets x, y, and z. <br />\n",
      "The assets pay 6%, 8%, and 10% simple interest, respectively.<br />\n",
      "The yearly interest is $12,950. <br />\n",
      "Twice as much money is invested at 6% than 10%. <br />\n",
      "How much money is invested in the three funds?\n",
      "\n",
      "One way to go about solving this is to first write down a system of equations. We know that the total investment is $175,000 so that\n",
      "\n",
      "    x + y + z = 175,000\n",
      "\n",
      "We know the total yearly interest is \n",
      "\n",
      "    .06x + .08y + .1z = 12,950\n",
      "\n",
      "We also know that twice as much is invested in x as z such that\n",
      "\n",
      "    x = 2z\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Thus we now have 3 equations and 3 unknowns.\n",
      "* We can solve this system using linear algebra\n",
      "* First we write the system in matrix form\n",
      "\n",
      "$$Y=\\left[\\begin{array}{c}\n",
      "          175000 \\cr\n",
      "          12950 \\cr\n",
      "          0\n",
      "\\end{array}\\right]$$\n",
      "\n",
      "$$B = \\left[\\begin{array}{c}\n",
      "        x \\cr\n",
      "        y \\cr\n",
      "        z \\cr\n",
      "\\end{array}\\right]$$\n",
      "\n",
      "$$X=\\left[\\begin{array}{ccc}\n",
      "          1 & 1 & 1 \\cr\n",
      "          .06 & .08 & .1 \\cr\n",
      "          1 & 0 & -2 \\cr\n",
      "\\end{array}\\right]$$\n",
      "\n",
      "Now we have in matrix form\n",
      "\n",
      "$$XB=Y$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Convince yourself that this is the original system of equations.\n",
      "* Suppose, for a minute, that this was a single equation problem in algebra.\n",
      "* How would we solve for $B$?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "The Solution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$B=X^{-1}Y$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Using NumPy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = np.array([[175000.], \n",
      "              [12950], \n",
      "              [0]])\n",
      "\n",
      "X = np.array([[1, 1, 1],\n",
      "              [.06, .08, .1],\n",
      "              [1, 0 , -2]])\n",
      "print\n",
      "print X\n",
      "print\n",
      "print Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "B = np.linalg.solve(X, Y)\n",
      "print B                 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Notice that we did **not** take a matrix inverse here.\n",
      "* Why not?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Matrix Inversion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* This is the linear algebra analogue to division\n",
      "* You don't need to concern yourself much with the details for this course\n",
      "* Just remember that you rarely want to do a matrix inversion on a computer\n",
      "* It is more numerically accurate to \"solve\" the system of equations\n",
      "* It takes less arithmetic operations\n",
      "* It is more more memory friendly\n",
      "\n",
      "**Inversion Properties**\n",
      "$$(A^{\\prime})^{-1}=(A^{-1})^{\\prime}$$\n",
      "$$(A^{\\prime})^{\\prime}=A$$\n",
      "$$(kA)^{\\prime}=k^{\\prime}A^{\\prime} \\text{ for nonzero scalar }k$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Gaussian Elimination"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* How do we solve these equations without taking an inverse?\n",
      "* One way is **Gaussian elimination**, or **Gauss Jordan elimination**\n",
      "* Example worked in class\n",
      "https://www.youtube.com/watch?v=2j5Ic2V7wq4\n",
      "\n",
      "    $$\\begin{aligned}\n",
      "    x + y - z &= 9 \\cr\n",
      "        y + 3z &= 3 \\cr\n",
      "        -x -2z &= 2 \\cr\n",
      "    \\end{aligned}$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "LU Decomposition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* How does a computer solve these equations with taking an inverse\n",
      "* To understand this, we need to understand the concept of a **matrix decomposition**\n",
      "* A **matrix decomposition** is a **factorization** of a matrix into a product of matrices\n",
      "* There are many different decompositions, depending on the problem you are solving\n",
      "* For example, if we have some matrix $X$, we may decompose it into two matrices $A$ and $B$ where\n",
      "\n",
      "$$AB=X$$\n",
      "\n",
      "* By putting certain restrictions on $A$ and $B$ we can use $A$ and $B$ to do things like avoiding inverses"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The decomposition used by `np.linalg.solve` command is the **LU decomposition**\n",
      "* The LU decomposition (or LU factorization)\n",
      "* Let $A$ be a square matrix, then the LU decomposition factors $A$ into two matrices $L$ and $U$ such that\n",
      "\n",
      "$$A=LU$$\n",
      "\n",
      "where $L$ is lower triangular and $U$ is upper triangular\n",
      "\n",
      "* Sometimes we might have to reorder $A$ for the decomposition to work\n",
      "* In this case we have the **LU Factorization with partial pivoting**\n",
      "\n",
      "$$PA=LU$$\n",
      "\n",
      "where $P$ is a permutation matrix that reorders the rows.\n",
      "\n",
      "* For example, the identity matrix is a permutation matrix that does nothing\n",
      "* Using $A$ from our Gaussian elimination example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[1, 1, -1],\n",
      "              [0, 1, 3],\n",
      "              [-1, 0, -2]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P = np.array([[1, 0, 0],[0, 1, 0],[0, 0, 1]])\n",
      "print P"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A == np.dot(P, A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Say we want to swap the first and second rows"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P = np.array([[0, 1, 0],[1, 0, 0],[0, 0, 1]])\n",
      "print P\n",
      "print\n",
      "print A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.dot(P, A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* In effect, this says, for the first row of $PA$ give me all the elements in the second column\n",
      "* In the second tow of $PA$ give me all the elements in the first column"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Continuing with the same example, the LU decomposition of $A$ looks like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import linalg\n",
      "\n",
      "P, L, U = linalg.lu(A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print P\n",
      "print\n",
      "print L\n",
      "print\n",
      "print U"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* You'll notice that $U$ is exactly the same as the row-echelon form of $AX=B$ that we saw in our Gaussian elimination example\n",
      "* The computer now does forward elimination just as we did to solve for"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The solution is then \n",
      "\n",
      "$$X = U^{-1}L^{-1}B$$\n",
      "\n",
      "* However, the computer does not need to compute any inverses\n",
      "* Since L and U are triangular matrices\n",
      "* $L^{-1}B$ is computed by forward substitution\n",
      "* Let $C = L^{-1}B$\n",
      "* $U^{-1}C$ is computed using back substitution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "B = np.array([[9],[3],[2]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C = np.dot(np.linalg.inv(L), B)\n",
      "print C"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.dot(np.linalg.inv(U), C)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Least Squares Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* What in the world does this have to do with least squares regression?\n",
      "* We are trying to find a $\\boldsymbol{b}$ such that the linear combination of the columns of $X$ gives $\\boldsymbol{y}$\n",
      "\n",
      "$$Y=Xb$$\n",
      "\n",
      "* If $y$ lies in the column space of $X$ then we can solve for $b$ exactly, as we showed above\n",
      "* Recall the usual notation for least squares regression using matrices\n",
      "\n",
      "$$\\boldsymbol{y}=X\\boldsymbol{b}+\\boldsymbol{e}$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "A detour into the geometry of Matrices"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Vectors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Note that bold terms are often used to differentiate vectors from scalars much as matrices are often uppercase\n",
      "* The $K$ elements of a column vector\n",
      "\n",
      "$$\\boldsymbol{a} = \\left[\\begin{array}{c}\n",
      "a_1\\cr\n",
      "a_2\\cr\n",
      "\\vdots\\cr\n",
      "a_k\\end{array}\\right]$$\n",
      "\n",
      "can be viewed as the coordinates of a point in a K-dimensional space\n",
      "\n",
      "* Two arithmetic operations are defined for vectors, **scalar multiplication** and **addition**\n",
      "* **Scalar multiplication**\n",
      "\n",
      "$$\\boldsymbol{a} = \\left[\\begin{array}{c}\n",
      "1\\cr\n",
      "2\\end{array}\\right]\\text{,}\\,\\,\\boldsymbol{a}^*=2\\boldsymbol{a}=\\left[\\begin{array}{c}\n",
      "2\\cr\n",
      "4\\end{array}\\right]\\text{,}\\,\\,\\boldsymbol{a}^{**}=-\\frac{1}{2}\\boldsymbol{a}=\\left[\\begin{array}{c}\n",
      "-\\frac{1}{2}\\cr\n",
      "-1\\end{array}\\right]$$\n",
      "\n",
      "* **Addition**\n",
      "$$\\boldsymbol{c}=\\boldsymbol{a}+\\boldsymbol{b}=\\left[\\begin{array}{c}\n",
      "1\\cr\n",
      "2\\end{array}\\right]+\\left[\\begin{array}{c}\n",
      "2\\cr\n",
      "1\\end{array}\\right]=\\left[\\begin{array}{c}\n",
      "3\\cr\n",
      "3\\end{array}\\right]$$\n",
      "* Geometrically"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(6,6))\n",
      "\n",
      "ax.plot([0, 1, 3],[0, 2, 3], color='b')\n",
      "ax.plot([0, 2, 3],[0, 1, 3], color='b')\n",
      "ax.plot([0, 2], [0, 4], color='b')\n",
      "ax.plot([0, 3], [0, 3], color='b')\n",
      "ax.arrow(0, 0, 1, 2, head_width=0.15, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
      "ax.arrow(0, 0, 2, 1, head_width=0.15, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
      "ax.arrow(0, 0, 3, 3, head_width=0.15, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
      "ax.arrow(0, 0, 2, 4, head_width=0.15, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
      "ax.annotate(\"$a$\", (.5, 1), (-10, 0), textcoords=\"offset points\", fontsize=16)\n",
      "ax.annotate(\"$a^*$\", (1.5, 3), (-15, 0), textcoords=\"offset points\", fontsize=16)\n",
      "ax.annotate(\"$b$\", (1, .5), (-2,-15), textcoords=\"offset points\", fontsize=16)\n",
      "ax.annotate(\"$c$\", (1.5, 1.5), (-2,-15), textcoords=\"offset points\", fontsize=16)\n",
      "ax.vlines(0, -1, 5)\n",
      "ax.hlines(0, -1, 5)\n",
      "ax.set_xlim(-1, 5)\n",
      "ax.set_ylim(-1, 5);\n",
      "ax.set_title(\"Vector Space - Standard Basis\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "The length of a vector"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The length, or **norm**, of a vector $\\boldsymbol{e}$ is \n",
      "\n",
      "$$\\begin{aligned}\n",
      "\\|e\\| &= \\sqrt{\\boldsymbol{e}^{\\prime}\\boldsymbol{e}} \\cr\n",
      "&= \\sqrt{\\sum_i{e_i^2}} \\cr\n",
      "&= \\sqrt{{e_1^2+e_2^2+e_3^2+\\dots+e_n^2}} \\cr\n",
      "\\end{aligned}$$\n",
      "\n",
      "* where have you seen this before?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* We can restate the least squares problem in these terms\n",
      "* The problem is to find the $\\boldsymbol{b}$ for which\n",
      "\n",
      "$$\\|\\boldsymbol{e}\\|=\\|y-X\\boldsymbol{b}\\|$$\n",
      "\n",
      "is as small as possible"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Orthogonality"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* General term for perpendicular\n",
      "* Two vectors $a$ and $b$ are orthogonal, written $a\\perp b$, if and only if\n",
      "\n",
      "$$a^{\\prime}b=b^{\\prime}a=0$$\n",
      "\n",
      "Let \n",
      "\n",
      "$$a = \\left[\\begin{array}{c}\n",
      "1\\cr\n",
      "3\\end{array}\\right]$$\n",
      "\n",
      "and \n",
      "\n",
      "$$b = \\left[\\begin{array}{c}\n",
      "3\\cr\n",
      "-1\\end{array}\\right]$$\n",
      "                 \n",
      "then\n",
      "\n",
      "$a^{\\prime}b=0$\n",
      "\n",
      "* Geometrically, this would look like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(6,6))\n",
      "\n",
      "ax.plot([0,1],[0, 3], color='b')\n",
      "ax.plot([0,3],[0,-1], color='b')\n",
      "ax.annotate(\"a\", (.5, 1.5), (-10, 0), textcoords=\"offset points\", fontsize=16)\n",
      "ax.annotate(\"b\", (1.5, -.5), (-2,-15), textcoords=\"offset points\", fontsize=16)\n",
      "ax.arrow(0, 0, 1, 3, head_width=0.15, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
      "ax.arrow(0, 0, 3, -1, head_width=0.15, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
      "ax.hlines(0, -2, 5)\n",
      "ax.vlines(0, -2, 5)\n",
      "ax.set_xlim(-2, 5)\n",
      "ax.set_ylim(-2, 5);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAFtCAYAAADI9OsfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x41e54d0>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The solution to $Y=X\\boldsymbol{b}+\\boldsymbol{e}$ is the the $\\boldsymbol{b}$ that makes $\\boldsymbol{e}$ perpendicular, or *orthogonal*, to $X\\boldsymbol{b}$\n",
      "* Why?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Solving Least Squares"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The problem then is to find a $b$ such that\n",
      "\n",
      "$$\\boldsymbol{e}\\perp X\\boldsymbol{b}$$\n",
      "\n",
      "* Worked in class\n",
      "* What is the shape of $(X^{\\prime}X)$ if $X$ is ($n\\times k$)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "The solution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* As we've seen the solution to the least squares problem is\n",
      "\n",
      "$$\\boldsymbol{b}=\\left(X^{\\prime}X\\right)^{-1}X^{\\prime}\\boldsymbol{y}$$\n",
      "\n",
      "* Recall that we almost never want to take an inverse\n",
      "* There are a few decompositions that are helpful here\n",
      "* First, we need the concept of a **pseudoinverse**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Moore-Penrose Pseudoinverse"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The psuedoinverse is a generalization of the common inverse matrix\n",
      "* Sometimes referred to as the **generalized inverse**\n",
      "* The Moore-Penrose is the most common\n",
      "* The pseudoinverse of $A$ is denoted $A^{+}$\n",
      "\n",
      "**Definition**\n",
      "\n",
      "The pseudoinverse of $A$, $A^{+}$ meets the following four conditions\n",
      "\n",
      "<ol style=\"list-style-type:decimal\">\n",
      "<li>$$AA^{+}A=A$$</li>\n",
      "<li>$$A^{+}AA^{+}=A^{+}$$</li>\n",
      "<li>$$(AA^{+})^{*}=AA^{+}$$</li>\n",
      "<li>$$(A^{+}A)^{*}=A^{+}A$$</li>\n",
      "</ol>\n",
      "\n",
      "\n",
      "**Properties**\n",
      "\n",
      "If $A$ is invertible, then $A^{-1}=A^+$\n",
      "$$(A^+)^+=A$$\n",
      "If the columns of $A$, an ($n \\times k$) matrix, are linearly independent (meaning $n\\ge k$), then\n",
      "$$A^+=(A^\\prime A)^{-1}A^{\\prime}$$\n",
      "\n",
      "Seen anywhere this could come in handy?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First let's simulate some data\n",
      "\n",
      "Suppose we want to fit a model of the form\n",
      "\n",
      "$$y = X\\beta + \\epsilon$$\n",
      "\n",
      "with\n",
      "\n",
      "$$\\epsilon \\sim N(0, 5)$$\n",
      "\n",
      "We are going to use a $\\beta$ of [2.5, -2.75] where 2.5 is the constant."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(12345)\n",
      "X = np.random.normal(0, 5, size=100)\n",
      "\n",
      "X = np.column_stack((np.ones(len(X)), X))\n",
      "beta = np.array([2.5, -2.75])\n",
      "\n",
      "# define y using our data-generating process\n",
      "\n",
      "y = np.dot(X, beta) + np.random.normal(0, 5**.5, size=len(X))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(7,5))\n",
      "\n",
      "ax.plot(X[:,1], y, 'bo')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[<matplotlib.lines.Line2D at 0x4663790>]"
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAbAAAAE1CAYAAACGM7VBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIglKYGJiIglKYGJiIglKYGJiIgl/X9QaUzBLx1WyAAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x4663810>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta = np.linalg.lstsq(X,y)[0]\n",
      "print beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 2.42316475 -2.76624733]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "SVD Decomposition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The Singular Value Decomposition or SVD is one way to solve the least squares problem\n",
      "* Indeed, the pseudoinverse is calculated using the SVD\n",
      "* The SVD of an $m\\times n$ matrix $A$ ($A\\in\\mathbb{R}^{m\\times n}$)\n",
      "\n",
      "$$USV^{*} = A$$\n",
      "\n",
      "* U is an $m\\times m $ unitary matrix\n",
      "* S is an $m\\times n$ diagonal matrix\n",
      "* The elements of S are the singular values (the square root of the eigenvalues) of $A^{*}A$ and $AA^{*}$\n",
      "* $V^{*}$ is an $n\\times n$ matrix which is the conjugate transpose of a unitary matrix $V$\n",
      "* A unitary matrix is any matrix such that\n",
      "\n",
      "$$B^{*}B=BB^{*}=I$$\n",
      "\n",
      "* Recall that if a matrix contains only real numbers then the conjugate transpose is equivalent to the transpose\n",
      "* The real analogue of a unitary matrix is an (orthogonal matrix)\n",
      "\n",
      "$$B^{\\prime}B=BB^{\\prime}=I$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Now that we know what an SVD is, the pseudoinverse of $A$ in terms of the SVD is\n",
      "\n",
      "$$A^{+}=VS^{+}U^{*}$$\n",
      "\n",
      "* Recall that S is an $m\\times n$ diagonal matrix, the pseudoinverse of this is formed by replacing the non-zero diagonal values with their reciprocals and transposing\n",
      "* This is easy to compute\n",
      "* Let's try"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "u, s, v = np.linalg.svd(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "u.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "(100, 100)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(2,)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([ 51.78257221,   9.99452709])"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Huh?\n",
      "* For the routine that numpy uses, s is of shape min($M$, $N$) to save space"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "(2, 2)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array([ 51.78257221,   9.99452709])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Sinv = np.zeros((2,100))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Sinv[:2,:2] = np.diag(1/s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pinvX = np.dot(np.dot(v.T, Sinv), u.T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.dot(pinvX, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 2.42316475 -2.76624733]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Or we could just use `np.linalg.pinv`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta = np.dot(np.linalg.pinv(X), y)\n",
      "print beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 2.42316475 -2.76624733]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* In the best case scenario and assuming $m>n$, which is true for least squares this is $O(mn^2)$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "QR Factorization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Again for $A\\in\\mathbb{R}^{m\\times n}$\n",
      "* The QR factorization is defined\n",
      "\n",
      "$$QR=A$$\n",
      "\n",
      "* Q is an $m\\times m$ orthogonal matrix\n",
      "* R is an $m\\times n$ upper triangular matrix\n",
      "* Since R is upper triangular, you may see\n",
      "\n",
      "$$R = \\left[\\begin{array}{c} R^{\\prime} \\cr\n",
      "       0 \\end{array}\\right]$$\n",
      "where $R^{\\prime}$ is $n\\times n$ upper triangular and 0 is an $(m -n) \\times n$ matrix of zeros"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* A helpful property of orthogonal matrices is that they preserve the norm (defined above)\n",
      "* This implies that\n",
      "\n",
      "$$\\|Qe\\|^2=(Qe)^{\\prime}(Qe)=e^{\\prime}Q^{\\prime}Qe=e^{\\prime}Ie=e^{\\prime}e=\\|e\\|^2$$\n",
      "\n",
      "* This follows from properties all defined above\n",
      "* Convince yourself"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* We can thus apply $Q$ to our residuals $\\|e\\|$\n",
      "* Assuming the system of equations $y=Xb$\n",
      "\n",
      "$\\|e\\|=\\|y-Xb\\|=\\|y-Q\\left[\\begin{array}{c}R \\cr 0\\end{array}\\right]b\\|=\\|Q^{\\prime}y-Q^{\\prime}Q\\left[\\begin{array}{c}R \\cr 0\\end{array}\\right]b\\|=\\|Q^{\\prime}y-\\left[\\begin{array}{c}R \\cr 0\\end{array}\\right]b\\|$\n",
      "\n",
      "If $Q^{\\prime}y=\\left[\\begin{array}{1}c_1 \\cr c_2\\end{array}\\right]$ and $b=\\left[\\begin{array}{1}b_1 \\cr b_2\\end{array}\\right]$ then\n",
      "\n",
      "$$\\|Q^{\\prime}y-\\left[\\begin{array}{c}R \\cr 0\\end{array}\\right]b\\|=\\|\\left[\\begin{array}{1}c_1 \\cr c_2\\end{array}\\right]-\\left[\\begin{array}{c}Rb_1 \\cr 0\\end{array}\\right]\\|=\\|\\left[\\begin{array}{c}c_1 - Rb_1 \\cr c_2\\end{array}\\right]\\|=\\|c_1-Rb_1\\|+\\|c_2\\|$$\n",
      "\n",
      "* Whew, okay\n",
      "* The least squares solution is then determined by solving $Rb_1=c_1$ using back-subsitution and $\\|c_2\\|$ are the residuals"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q, R = np.linalg.qr(X)\n",
      "c_1 = np.dot(Q.T, y)\n",
      "\n",
      "beta = np.linalg.solve(R, c_1)\n",
      "print beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 2.42316475 -2.76624733]\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* In a stats class, you may see `c_1` referred to as \"effects\"\n",
      "* The QR Factorization is usually $O(n^3)$"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}