{
 "metadata": {
  "name": "",
  "signature": "sha256:23664cfa2aad1dd4d1e44b466cb6c615767b0f8b4e426c416e6fe6e4fcd21e14"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Unsupervised Learning Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* So far, we have seen supervised learning and statistical models with an outcome variable\n",
      "* In unsupervised learning, there is no outcome variable (**class**, **target**, or **label**)\n",
      "* One type of unsupervised learning is that of **clustering**, which we are going to look at in detail\n",
      "* Clustering is the task of gathering samples into groups of similar samples according to some predefined similarity (distance) or dissimilarity measure\n",
      "* Some examples of clustering problems from the [scikit-learn tutorial](http://scikit-learn.github.io/scikit-learn-tutorial/) are\n",
      "  * Building customer profiles for market analysis\n",
      "  * Grouping related web news (e.g. Google News) and websearch results\n",
      "  * Grouping related stock quotes for investment portfolio management\n",
      "  * Can be used as a preprocessing step for recommender systems"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "The $k$-Means Algorithm"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Suppose we have some input data that we want to divide into $k$ categories\n",
      "* The value of $k$ is known\n",
      "  * For example, we have medical test results for a number of people for 3 diseases\n",
      "  * We want to see how well the tests identify the 3 diseases\n",
      "* Allocate $k$ cluster centers to the **input space** such that there are three centers in the middle of each cluster\n",
      "* We need an algorithm to tell us what the clusters are and where there centers are"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Recall that with supervised learning, we defined some kind of error measure between our \"targets\" and the \"outputs\" of the model\n",
      "* We will do something similar with unsupervised learning even though we do not have a \"target\"\n",
      "* First, we will need to define a **distance measure**\n",
      "  * For now, we'll use Euclidean distance again\n",
      "* Second, we need the **mean average**\n",
      "  * using a distance measure we can compute the central point of a set of datapoints (assuming space is flat)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* But how do we position the cluster centers?\n",
      "* We compute the mean point of each cluster, $\\boldsymbol{u}_{c(i)}$, and put the cluster center there\n",
      "* This is equivalent to minimizing the Euclidean distance (sum-of-squares error) from each datapoint to its cluster center\n",
      "* Which cluster does each datapoint belong to?\n",
      "* Each datapoint belongs to the cluster center that it is closest to\n",
      "* The $k$-Means algorithm is iterative and this will change as we update the cluster centers"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "The $k$-Means Algorithm"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Initialization**\n",
      "  * choose a value for $k$\n",
      "  * choose $k$ random positions in the input space\n",
      "  * assign the cluster centers $u_j$ to those positions\n",
      "* **Learning**\n",
      "  * repeat until cluster centers stop moving:\n",
      "    * for each datapoint $\\boldsymbol{x_i}$:\n",
      "      * compute the distance to each cluster center\n",
      "      * assign the datapoint to the nearest cluster center with distance\n",
      "\n",
      "        $d_i=\\min_jd(\\boldsymbol{x}_i, \\boldsymbol{u}_j)$\n",
      "        \n",
      "    * for each cluster center:\n",
      "      * move the position of the center to the mean of the points in that cluster\n",
      "        \n",
      "        $\\mu_j=\\frac{1}{N_j}\\sum_{i=1}^{N_j}\\boldsymbol{x}_i$\n",
      "        \n",
      "* **Usage**\n",
      "  * for each test point\n",
      "    * comptue the distance to each cluster center\n",
      "    * assign the datapoint to the nearest cluster center with distance\n",
      "    \n",
      "      $d_j=\\min_jd(\\boldsymbol{x}_i, \\boldsymbol{u}_j)$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "An Example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "data = [(.50, .08), (.10, .21), (.15, .17), \n",
      "        (.70, .31), (.68, .37), (.36, .47), \n",
      "        (.33, .50), (.12, .80), (.18, .80),\n",
      "        (.65, .78), (.68, .78), (.70, .75)]\n",
      "data = np.array(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(6,6))\n",
      "\n",
      "ax.scatter(*data.T);\n",
      "ax.grid(False);\n",
      "ax.set_xlim(0, 1)\n",
      "ax.set_ylim(0, 1);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Using SciPy For $k$-Means clustering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* scipy has a clustering module called `cluster`\n",
      "* This module contains a submodule called `vq` and `hierarchy`\n",
      "* `vq` stands for vector quantization and k-means\n",
      "* `hierarchy` contains algorithms for hierarchical clustering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import cluster as sp_cluster"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Normalize the data as we have before\n",
      "* There's yet another method for this in `cluster`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Aside**: A note on normalization\n",
      "* Often it is the case that the algorithm you are using is dependent on certain assumptions about the data\n",
      "* In these cases, you must normalize the data in such a way as to satisfy the assumptions of the algorithm"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wdata = sp_cluster.vq.whiten(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(12345)\n",
      "cluster1 = sp_cluster.vq.kmeans2(wdata, 4, missing='raise')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(cluster1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(12)\n",
      "cluster2 = sp_cluster.vq.kmeans2(wdata, 4, missing='raise', \n",
      "minit='points')\n",
      "cluster3 = sp_cluster.vq.kmeans2(wdata, 4, missing='raise')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Local Minima"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "marker = {0 : \"x\", 1 : \"D\", 2 : \"^\", 3 : \"o\"}\n",
      "size = {0 : 24, 1 : 24, 2 : 42, 3 : 24}\n",
      "\n",
      "fig, axes = plt.subplots(2, 2, figsize=(8,8), sharex=True, sharey=True)\n",
      "axes[0,0].scatter(*wdata.T)\n",
      "for i in range(4):\n",
      "    axes[0,1].scatter(*wdata[cluster1[1] == i].T, marker=marker[i], s=size[i])\n",
      "axes[0,1].scatter(*cluster1[0].T, marker=\"x\", c=\"red\", s=64, lw=3, alpha=.4)\n",
      "                  \n",
      "for i in range(4):\n",
      "    axes[1,0].scatter(*wdata[cluster2[1] == i].T, marker=marker[i], s=size[i])\n",
      "axes[1,0].scatter(*cluster2[0].T, marker=\"x\", c=\"red\", s=64, lw=3, alpha=.4)\n",
      "\n",
      "for i in range(4):\n",
      "    axes[1,1].scatter(*wdata[cluster3[1] == i].T, marker=marker[i], s=size[i])\n",
      "axes[1,1].scatter(*cluster3[0].T, marker=\"x\", c=\"red\", s=64, lw=3, alpha=.4);\n",
      "\n",
      "axes[0,0].set_xticks([])\n",
      "axes[0,0].set_yticks([])\n",
      "fig.tight_layout();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Using scikit-learn"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Let's look again at the Iris datasets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_iris\n",
      "iris = load_iris()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* scikit-learn also has a [cluster module](http://scikit-learn.org/stable/modules/clustering.html) with many popular algorithms, including $k$-Means"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans\n",
      "from numpy.random import RandomState"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rng = RandomState(12345)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = iris.data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* normalize the data\n",
      "* scikit-learn provides a [suite of preprocessing utilities](http://scikit-learn.org/dev/modules/preprocessing.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaled_data = preprocessing.scale(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaled_data.mean(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaled_data.var(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kmeans = KMeans(3, random_state=rng).fit(scaled_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Computed values in scikit-learn have an `_` appended"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(kmeans.cluster_centers_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(kmeans.labels_[:50])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(kmeans.labels_[50:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import cycle\n",
      "\n",
      "def plot_2D(data, target, target_names, ax):\n",
      "    colors = cycle('rgbcmykw')\n",
      "    target_ids = range(len(target_names))\n",
      "    for i, c, label in zip(target_ids, colors, target_names):\n",
      "        ax.scatter(data[target == i, 0], data[target == i, 1],\n",
      "                   c=c, label=label)\n",
      "    ax.legend()\n",
      "\n",
      "fig, ax = plt.subplots()\n",
      "plot_2D(scaled_data[:,:2], kmeans.labels_, [\"c0\", \"c1\", \"c2\"], ax)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots()\n",
      "plot_2D(scaled_data[:,2:], kmeans.labels_, [\"c0\", \"c1\", \"c2\"], ax)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Pipelines"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* scikit-learn provides a nice interface\n",
      "* The [Pipeline](http://scikit-learn.org/dev/modules/generated/sklearn.pipeline.Pipeline.html) class behaves like a sequential classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Doing the pre-processing this way allows the *same* transform to be applied to different data later"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = preprocessing.StandardScaler().fit(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris_clf = Pipeline([(\"scale\", scaler),\n",
      "                     (\"cluster\", KMeans(3))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The Pipeline object behaves like a classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = iris_clf.fit(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.named_steps[\"cluster\"].labels_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Hierarchical Clustering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Hierarchical clustering aims to build nested clusters by merging or splitting clusters successively\n",
      "* There is *top-down*, or *divisive* clustering\n",
      "  * top-down are usually better suited for a small number of cluster\n",
      "* Or *bottom-up*, *agglomerative* clustering\n",
      "  * bottom-up tend to work better on a large number of clusters\n",
      "  * ie., when each cluster only has a few observations"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Ward Clustering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* An example of agglomerative hierarchical clustering is Ward's method\n",
      "* In Ward's method, we start with the data such that each observation is its own cluster\n",
      "* At each step, we merge the pairs of observations for which the within-cluster variance is minimized"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Recall that the variance of a random variable $\\boldsymbol{X}$ is defined\n",
      "\n",
      "$$\\begin{aligned}\n",
      "var(X)&=\\mathbb{E}[(X-\\mu)(X-\\mu)] \\cr\n",
      "&=\\mathbb{E}[(X-\\mu^2)] \\cr\n",
      "\\end{aligned}$$\n",
      "\n",
      "* That is, the variance is the *expected* squared deviation about the mean"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.array([12,13,14,15,16,17.])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X - np.mean(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(X - np.mean(X))**2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1./len(X)*(X - np.mean(X))**2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(1./len(X)*(X - np.mean(X))**2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.var()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Example: In the Cage with Cage"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import ndimage\n",
      "img = ndimage.imread(\"cage.jpeg\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(8,8))\n",
      "ax.imshow(img)\n",
      "ax.grid(False)\n",
      "ax.set_xticks([])\n",
      "ax.set_yticks([]);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* If we use the flatten argument, we get a grayscale image\n",
      "* Grayscale images are images where each pixel is a single sample\n",
      "* In this case each sample is an intensity, a number from 0 to 256"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cage = ndimage.imread(\"cage.jpeg\", flatten=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cage.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(cage.min(), cage.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Crop the image to be square"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cage.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cage.shape[1]/2 - 314/2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "center = cage.shape[1]/2\n",
      "width_range = center - cage.shape[0]/2, center + cage.shape[0]/2\n",
      "cage = cage[:,width_range[0]:width_range[1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cage.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Downsample the image by a factor of 4\n",
      "#cage = cage[::2, ::2] + cage[1::2, ::2] + cage[::2, 1::2] + cage[1::2, 1::2]\n",
      "X = np.reshape(cage, (-1, 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cage.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Define the adjaceny matrix, of the data. \n",
      "* The adjency matrix tells where pixels are connected to their neighbors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.image import grid_to_graph"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_to_graph(3, 3, return_as=np.ndarray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "connectivity = grid_to_graph(*cage.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "connectivity"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(connectivity.col), len(connectivity.row)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Compute clustering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    from sklearn.cluster import Ward\n",
      "except ImportError:\n",
      "    from sklearn.cluster import AgglomerativeClustering as Ward"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "connectivity"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_clusters = 15  # number of regions\n",
      "\n",
      "# make a model\n",
      "ward = Ward(n_clusters=n_clusters, connectivity=connectivity)\n",
      "ward.fit(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label = ward.labels_.reshape(cage.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Number of pixels: \", label.size)\n",
      "print(\"Number of clusters: \", np.unique(label).size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(6,6))\n",
      "\n",
      "ax.imshow(cage, cmap=plt.cm.gray)\n",
      "for l in range(n_clusters):\n",
      "    ax.contour(label == l, contours=1,\n",
      "               colors=[plt.cm.spectral(l / float(n_clusters)), ])\n",
      "ax.set_xticks(())\n",
      "ax.set_yticks(());"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}