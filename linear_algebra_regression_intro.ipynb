{
 "metadata": {
  "name": "linear_algebra_regression_intro"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Linear Algebra Review"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Transposing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recall that $\\prime$ indicates taking the transpose of a matrix. This just means to swap the rows and the columns of a matrix. So that if \n",
      "\n",
      "$$A = \\left[\\begin{array}{ccc}\n",
      "1 & 2 & 3 \\cr\n",
      "      4 & 5 & 6 \\cr\n",
      "      7 & 8 & 9\\end{array}\\right]$$\n",
      "\n",
      "then\n",
      "\n",
      "$$A^{\\prime} = \\left[\\begin{array}{ccc}\n",
      "      1 & 4 & 7 \\cr\n",
      "      2 & 5 & 8 \\cr\n",
      "      3 & 6 & 9\\end{array}\\right]$$\n",
      "\n",
      "**Properties**\n",
      "\n",
      "$$(A^{\\prime})^{\\prime}=A$$\n",
      "$$(A+B)^{\\prime}=A^{\\prime}+B^{\\prime}$$\n",
      "$$(AB)^{\\prime}=B^{\\prime}A^{\\prime}$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Triangular Matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* A triangular matrix is a square matrix in which all of the elements above or below the diagonal are zero\n",
      "* **Lower** triangular matrix\n",
      "$$L=\\left[\\begin{array}{c c c c c}\n",
      "x_{1,1} & & & & 0 \\cr\n",
      "x_{2,1} & x_{2,2} & & &  \\cr\n",
      "x_{3,1} & x_{3,2} & \\ddots & &  \\cr\n",
      "\\vdots & \\vdots & \\ddots & \\ddots & \\cr\n",
      "x_{n,1} & x_{n,2} & \\cdots & x_{n,n-1} & x_{n,n} \\cr\n",
      "\\end{array}\\right]$$\n",
      "* **Upper** triangular matrix\n",
      "$$U=\\left[\\begin{array}{c c c c c}\n",
      "x_{1,1} & x_{1,2} & \\cdots & x_{1, n-1} & x_{1, n} \\cr\n",
      "& x_{2,2} & x_{2,3} & \\cdots & x_{2,n}  \\cr\n",
      "& & \\ddots & \\ddots & \\vdots \\cr\n",
      "& & & \\ddots & x_{n-1,n} \\cr\n",
      "0 &  & & & x_{n,n} \\cr\n",
      "\\end{array}\\right]$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Multiplication"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Matrix multiplication takes the rows of the matrix that by which you are pre-multiplying and takes linear combination of each row with each column of the matrix by which you are post-multiplying. \n",
      "* To be **conformable** the columns of the $1^{\\text{st}}$ matrix must be equal to the rows of the $2^{\\text{nd}}$ matrix. \n",
      "* The dot product $AB$, $A$ must have the same number of columns as $B$ has rows. \n",
      "* $AB$ has the same number of rows as $A$ and the same number of columns as $B$.  \n",
      "* If A were ($3\\times2$) and B were ($2\\times2$), the result $AB$ would be ($3\\times1$)\n",
      "* For example,\n",
      "\n",
      "$$A = \\left[\\begin{array}{c c}\n",
      "        2 & 3.5 \\cr\n",
      "        -0.5 & 2.1 \\cr\n",
      "        9 & 0 \\cr\n",
      "\\end{array}\\right]$$\n",
      "\n",
      "and let \n",
      "\n",
      "$$B = \\left[\\begin{array}{c c}\n",
      "            1 & 1.5 \\cr\n",
      "            -4.5 & 5 \\cr\n",
      "\\end{array}\\right]$$\n",
      "\n",
      "Then \n",
      "\n",
      "$$AB=\\left[\\begin{array}{c c}\n",
      "    -13.75 & 20.5 \\cr\n",
      "    -9.95 & 9.75 \\cr\n",
      "        9 & 13.5 \\cr\n",
      "\\end{array}\\right]$$\n",
      "\n",
      "Explicitly, this is\n",
      "\n",
      "$$\\begin{aligned}\n",
      "\\color{blue}{\\text{Row 1, Column 1}} \\cr\n",
      "2\\color{red}{\\times}1 + 3.5\\color{red}{\\times} -4.5 &= -13.75 \\cr\n",
      "\\color{blue}{\\text{Row 1, Column 2}} \\cr\n",
      "2\\color{red}{\\times}1.5 + 3.5\\color{red}{\\times} 5 &= 20.5 \\cr\n",
      "\\color{blue}{\\text{Row 2, Column 1}} \\cr\n",
      "-0.5\\color{red}{\\times}1 + 2.1\\color{red}{\\times} -4.5 &= -9.95 \\cr\n",
      "\\color{blue}{\\text{Row 2, Column 2}} \\cr\n",
      "-0.5 \\color{red}{\\times} 1.5 + 2.1\\color{red}{\\times} 5 &= 9.75 \\cr\n",
      "\\color{blue}{\\text{Row 3, Column 1}} \\cr\n",
      "9 \\color{red}{\\times} 1 + 0 \\color{red}{\\times} -4.5 &= 9 \\cr\n",
      "\\color{blue}{\\text{Row 3, Column 2}} \\cr\n",
      "9 \\color{red}{\\times} 1.5 + 0 \\color{red}{\\times} 5 &= 13.5\n",
      "\\end{aligned}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's check with NumPy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[2, 3.5],\n",
      "              [-.5, 2.1],\n",
      "              [9, 0]])\n",
      "\n",
      "B = np.array([[1, 1.5],\n",
      "              [-4.5, 5]])\n",
      "print A\n",
      "print\n",
      "print B\n",
      "print\n",
      "print np.dot(A, B)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Systems of Equations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose you know that a total of `$`175,000 is invested in three assets x, y, and z. <br />\n",
      "The assets pay 6%, 8%, and 10% simple interest, respectively.<br />\n",
      "The yearly interest is $12,950. <br />\n",
      "Twice as much money is invested at 6% than 10%. <br />\n",
      "How much money is invested in the three funds?\n",
      "\n",
      "One way to go about solving this is to first write down a system of equations. We know that the total investment is $175,000 so that\n",
      "\n",
      "    x + y + z = 175,000\n",
      "\n",
      "We know the total yearly interest is \n",
      "\n",
      "    .06x + .08y + .1z = 12,950\n",
      "\n",
      "We also know that twice as much is invested in x as z such that\n",
      "\n",
      "    x = 2z\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Thus we now have 3 equations and 3 unknowns.\n",
      "* We can solve this system using linear algebra\n",
      "* First we write the system in matrix form\n",
      "\n",
      "$$Y=\\left[\\begin{array}{c}\n",
      "          175000 \\cr\n",
      "          12950 \\cr\n",
      "          0\n",
      "\\end{array}\\right]$$\n",
      "\n",
      "$$B = \\left[\\begin{array}{c}\n",
      "        x \\cr\n",
      "        y \\cr\n",
      "        z \\cr\n",
      "\\end{array}\\right]$$\n",
      "\n",
      "$$X=\\left[\\begin{array}{ccc}\n",
      "          1 & 1 & 1 \\cr\n",
      "          .06 & .08 & .1 \\cr\n",
      "          1 & 0 & -2 \\cr\n",
      "\\end{array}\\right]$$\n",
      "\n",
      "Now we have in matrix form\n",
      "\n",
      "$$XB=Y$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Convince yourself that this is the original system of equations.\n",
      "* Suppose, for a minute, that this was a single equation problem in algebra.\n",
      "* How would we solve for $B$?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "The Solution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$B=X^{-1}Y$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Using NumPy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = np.array([[175000.], \n",
      "              [12950], \n",
      "              [0]])\n",
      "\n",
      "X = np.array([[1, 1, 1],\n",
      "              [.06, .08, .1],\n",
      "              [1, 0 , -2]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "B = np.linalg.solve(X, Y)\n",
      "print B                    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Notice that we did **not** take a matrix inverse here.\n",
      "* Why not?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Matrix Inversion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* This is the linear algebra analogue to division\n",
      "* You don't need to concern yourself much with the details for this course\n",
      "* Just remember that you rarely want to do a matrix inversion on a computer\n",
      "* It is more numerically accurate to \"solve\" the system of equations\n",
      "* It takes less arithmetic operations\n",
      "* It is more more memory friendly\n",
      "\n",
      "**Inversion Properties**\n",
      "$$(A^{\\prime})^{-1}=(A^{-1})^{\\prime}$$\n",
      "$$(A^{\\prime})^{\\prime}=A$$\n",
      "$$(kA)^{\\prime}=k^{\\prime}A^{\\prime} \\text{ for nonzero scalar }k$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Gaussian Elimination"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* How do we solve these equations without taking an inverse?\n",
      "* One way is **Gaussian elimination**, or **Gauss Jordan elimination**\n",
      "* Example worked in class\n",
      "https://www.youtube.com/watch?v=2j5Ic2V7wq4\n",
      "\n",
      "    $$\\begin{aligned}\n",
      "    x + y - z &= 9 \\cr\n",
      "        y + 3z &= 3 \\cr\n",
      "        -x -2x &= 2 \\cr\n",
      "    \\end{aligned}$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "LU Decomposition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* How does a computer solve these equations with taking an inverse\n",
      "* To understand this, we need to understand the concept of a **matrix decomposition**\n",
      "* A **matrix decomposition** is a **factorization** of a matrix into a product of matrices\n",
      "* There are many different decompositions, depending on the problem you are solving\n",
      "* For example, if we have some matrix $X$, we may decompose it into two matrices $A$ and $B$ where\n",
      "\n",
      "$$AB=X$$\n",
      "\n",
      "* By putting certain restrictions on $A$ and $B$ we can use $A$ and $B$ to do things like avoiding inverses"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The decomposition used by `np.linalg.solve` command is the **LU decomposition**\n",
      "* The LU decomposition (or LU factorization)\n",
      "* Let $A$ be a square matrix, then the LU decomposition factors $A$ into two matrices $L$ and $U$ such that\n",
      "\n",
      "$$A=LU$$\n",
      "\n",
      "where $L$ is lower triangular and $U$ is upper triangular\n",
      "\n",
      "* Sometimes we might have to reorder $A$ for the decomposition to work\n",
      "* In this case we have the **LU Factorization with partial pivoting**\n",
      "\n",
      "$$PA=LU$$\n",
      "\n",
      "where $P$ is a permutation matrix that reorders the rows.\n",
      "\n",
      "* For example, the identity matrix is a permutation matrix that does nothing\n",
      "* Using $A$ from our Gaussian elimination example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[1, 1, -1],\n",
      "              [0, 1, 3],\n",
      "              [-1, 0, -2]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P = np.array([[1, 0, 0],[0, 1, 0],[0, 0, 1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A == np.dot(P, A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Say we want to swap the first and second rows"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P = np.array([[0, 1, 0],[1, 0, 0],[0, 0, 1]])\n",
      "P"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.dot(P, A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* In effect, this says, for the first row of $PA$ give me all the elements in the second column\n",
      "* In the second tow of $PA$ give me all the elements in the first column"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Continuing with the same example, the LU decomposition of $A$ looks like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import linalg\n",
      "\n",
      "P, L, U = linalg.lu(A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print P\n",
      "print\n",
      "print L\n",
      "print\n",
      "print U"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* You'll notice that $U$ is exactly the same as the row-echelon form of $AX=B$ that we saw in our Gaussian elimination example\n",
      "* The computer now does forward elimination just as we did to solve for"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The solution is then \n",
      "\n",
      "$$X = U^{-1}L^{-1}B$$\n",
      "\n",
      "* However, the computer does not need to compute any inverses\n",
      "* Since L and U are triangular matrices\n",
      "* $L^{-1}B$ is computed by forward substitution\n",
      "* Let $C = L^{-1}B$\n",
      "* $U^{-1}C$ is computed using back substitution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "B = np.array([[9],[3],[2]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C = np.dot(np.linalg.inv(L), B)\n",
      "print C"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.dot(np.linalg.inv(U), C)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Least Squares Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* What in the world does this have to do with least squares regression?\n",
      "* We are trying to find a $\\boldsymbol{b}$ such that the linear combination of the columns of $X$ gives $\\boldsymbol{y}$\n",
      "\n",
      "$$Y=Xb$$\n",
      "\n",
      "* If $y$ lies in the column space of $X$ then we can solve for $b$ exactly, as we showed above\n",
      "* Recall the usual notation for least squares regression using matrices\n",
      "\n",
      "$$\\boldsymbol{y}=X\\boldsymbol{b}+\\boldsymbol{e}$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "A detour into the geometry of Matrices"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Vectors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Note that bold terms are often used to differentiate vectors from scalars much as matrices are often uppercase\n",
      "* The $K$ elements of a column vector\n",
      "\n",
      "$$\\boldsymbol{a} = \\left[\\begin{array}{c}\n",
      "a_1\\cr\n",
      "a_2\\cr\n",
      "\\vdots\\cr\n",
      "a_k\\end{array}\\right]$$\n",
      "\n",
      "can be viewed as the coordinates of a point in a K-dimensional space\n",
      "\n",
      "* Two arithmetic operations are defined for vectors, **scalar multiplication** and **addition**\n",
      "* **Scalar multiplication**\n",
      "\n",
      "$$\\boldsymbol{a} = \\left[\\begin{array}{c}\n",
      "1\\cr\n",
      "2\\end{array}\\right]\\text{,}\\,\\,\\boldsymbol{a}^*=2\\boldsymbol{a}=\\left[\\begin{array}{c}\n",
      "2\\cr\n",
      "4\\end{array}\\right]\\text{,}\\,\\,\\boldsymbol{a}^{**}=-\\frac{1}{2}\\boldsymbol{a}=\\left[\\begin{array}{c}\n",
      "-\\frac{1}{2}\\cr\n",
      "-1\\end{array}\\right]$$\n",
      "\n",
      "* **Addition**\n",
      "$$\\boldsymbol{c}=\\boldsymbol{a}+\\boldsymbol{b}=\\left[\\begin{array}{c}\n",
      "1\\cr\n",
      "2\\end{array}\\right]+\\left[\\begin{array}{c}\n",
      "2\\cr\n",
      "1\\end{array}\\right]=\\left[\\begin{array}{c}\n",
      "3\\cr\n",
      "3\\end{array}\\right]$$\n",
      "* Geometrically"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(6,6))\n",
      "\n",
      "ax.plot([0, 1, 3],[0, 2, 3], color='b')\n",
      "ax.plot([0, 2, 3],[0, 1, 3], color='b')\n",
      "ax.plot([0, 2], [0, 4], color='b')\n",
      "ax.plot([0, 3], [0, 3], color='b')\n",
      "ax.arrow(0, 0, 1, 2, head_width=0.15, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
      "ax.arrow(0, 0, 2, 1, head_width=0.15, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
      "ax.arrow(0, 0, 3, 3, head_width=0.15, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
      "ax.arrow(0, 0, 2, 4, head_width=0.15, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
      "ax.annotate(\"$a$\", (.5, 1), (-10, 0), textcoords=\"offset points\", fontsize=16)\n",
      "ax.annotate(\"$a^*$\", (1.5, 3), (-15, 0), textcoords=\"offset points\", fontsize=16)\n",
      "ax.annotate(\"$b$\", (1, .5), (-2,-15), textcoords=\"offset points\", fontsize=16)\n",
      "ax.annotate(\"$c$\", (1.5, 1.5), (-2,-15), textcoords=\"offset points\", fontsize=16)\n",
      "ax.vlines(0, -1, 5)\n",
      "ax.hlines(0, -1, 5)\n",
      "ax.set_xlim(-1, 5)\n",
      "ax.set_ylim(-1, 5);\n",
      "ax.set_title(\"Vector Space - Standard Basis\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "The length of a vector"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The length, or **norm**, of a vector $\\boldsymbol{e}$ is \n",
      "\n",
      "$$\\begin{aligned}\n",
      "\\|e\\| &= \\sqrt{\\boldsymbol{e}^{\\prime}\\boldsymbol{e}} \\cr\n",
      "&= \\sqrt{\\sum_i{e_i^2}} \\cr\n",
      "&= \\sqrt{{e_1^2+e_2^2+e_3^2+\\dots+e_n^2}} \\cr\n",
      "\\end{aligned}$$\n",
      "\n",
      "* where have you seen this before?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* We can restate the least squares problem in these terms\n",
      "* The problem is to find the $\\boldsymbol{b}$ for which\n",
      "\n",
      "$$\\|\\boldsymbol{e}\\|=\\|y-X\\boldsymbol{b}\\|$$\n",
      "\n",
      "is as small as possible"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Orthogonality"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* General term for perpendicular\n",
      "* Two vectors $a$ and $b$ are orthogonal, written $a\\perp b$, if and only if\n",
      "\n",
      "$$a^{\\prime}b=b^{\\prime}a=0$$\n",
      "\n",
      "Let \n",
      "\n",
      "$$a = \\left[\\begin{array}{c}\n",
      "1\\cr\n",
      "3\\end{array}\\right]$$\n",
      "\n",
      "and \n",
      "\n",
      "$$b = \\left[\\begin{array}{c}\n",
      "3\\cr\n",
      "-1\\end{array}\\right]$$\n",
      "                 \n",
      "then\n",
      "\n",
      "$a^{\\prime}b=0$\n",
      "\n",
      "* Geometrically, this would look like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(6,6))\n",
      "\n",
      "ax.plot([0,1],[0, 3], color='b')\n",
      "ax.plot([0,3],[0,-1], color='b')\n",
      "ax.annotate(\"a\", (.5, 1.5), (-10, 0), textcoords=\"offset points\", fontsize=16)\n",
      "ax.annotate(\"b\", (1.5, -.5), (-2,-15), textcoords=\"offset points\", fontsize=16)\n",
      "ax.arrow(0, 0, 1, 3, head_width=0.15, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
      "ax.arrow(0, 0, 3, -1, head_width=0.15, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
      "ax.hlines(0, -2, 5)\n",
      "ax.vlines(0, -2, 5)\n",
      "ax.set_xlim(-2, 5)\n",
      "ax.set_ylim(-2, 5);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The solution to $Y=X\\boldsymbol{b}+\\boldsymbol{e}$ is the the $\\boldsymbol{b}$ that makes $\\boldsymbol{e}$ perpendicular, or *orthogonal*, to $X\\boldsymbol{b}$\n",
      "* Why?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Solving Least Squares"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The problem then is to find a $b$ such that\n",
      "\n",
      "$$\\boldsymbol{e}\\perp X\\boldsymbol{b}$$\n",
      "\n",
      "* Worked in class\n",
      "* What is the shape of $(X^{\\prime}X)$ if $X$ is ($n\\times k$)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "The solution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* As we've seen the solution to the least squares problem is\n",
      "\n",
      "$$\\boldsymbol{b}=\\left(X^{\\prime}X\\right)^{-1}X^{\\prime}\\boldsymbol{y}$$\n",
      "\n",
      "* Recall that we almost never want to take an inverse\n",
      "* There are a few decompositions that are helpful here\n",
      "* First, we need the concept of a **pseudoinverse**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Moore-Penrose Pseudoinverse"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The psuedoinverse is a generalization of the common inverse matrix\n",
      "* Sometimes referred to as the **generalized inverse**\n",
      "* The Moore-Penrose is the most common\n",
      "* The pseudoinverse of $A$ is denoted $A^{+}$\n",
      "\n",
      "**Properties**\n",
      "\n",
      "If $A$ is invertible, then $A^{\\prime}=A^+$\n",
      "$$(A^+)^+=A$$\n",
      "If the columns of $A$, an ($n \\times k$) matrix, are linearly independent (meaning $n\\ge k$), then\n",
      "$$A^+=(A^\\prime A)^{-1}A^{\\prime}$$\n",
      "\n",
      "Seen anywhere this could come in handy?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "SVD Decomposition"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "QR Decomposition"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}